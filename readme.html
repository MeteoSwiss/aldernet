
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Aldernet &#8212; Aldernet 0.1.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Installation" href="installation.html" />
    <link rel="prev" title="Welcome to Aldernet’s documentation!" href="index.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="aldernet">
<h1>Aldernet<a class="headerlink" href="#aldernet" title="Permalink to this heading">¶</a></h1>
<a class="reference external image-reference" href="https://meteoswiss.github.io/aldernet/"><img alt="View GitHub IO Page" src="https://img.shields.io/badge/View-GitHub%20IO%20Page-blue" /></a>
<section id="start-developing">
<h2>Start developing<a class="headerlink" href="#start-developing" title="Permalink to this heading">¶</a></h2>
<p>Once you created or cloned this repository, make sure the installation is running properly. Install the package dependencies with the provided script <code class="docutils literal notranslate"><span class="pre">setup_env.sh</span></code>.
Check available options with</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tools/setup_env.sh -h
</pre></div>
</div>
<p>We distinguish pinned installations based on exported (reproducible) environments and free installations where the installation
is based on top-level dependencies listed in <code class="docutils literal notranslate"><span class="pre">requirements/requirements.yml</span></code>. If you start developing, you might want to do an unpinned installation and export the environment:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tools/setup_env.sh -u -e -n &lt;package_env_name&gt;
</pre></div>
</div>
<p><em>Hint</em>: If you are the package administrator, it is a good idea to understand what this script does, you can do everything manually with <code class="docutils literal notranslate"><span class="pre">conda</span></code> instructions.</p>
<p><em>Hint</em>: Use the flag <code class="docutils literal notranslate"><span class="pre">-m</span></code> to speed up the installation using mamba. Of course you will have to install mamba first (we recommend to install mamba into your base
environment <code class="docutils literal notranslate"><span class="pre">conda</span> <span class="pre">install</span> <span class="pre">-c</span> <span class="pre">conda-forge</span> <span class="pre">mamba</span></code>. If you install mamba in another (maybe dedicated) environment, environments installed with mamba will be located
in <code class="docutils literal notranslate"><span class="pre">&lt;miniconda_root_dir&gt;/envs/mamba/envs</span></code>, which is not very practical.</p>
<p>The package itself is installed with <code class="docutils literal notranslate"><span class="pre">pip</span></code>. For development, install in editable mode:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>conda activate &lt;package_env_name&gt;
pip install --editable .
</pre></div>
</div>
<p><em>Warning:</em> Make sure you use the right pip, i.e. the one from the installed conda environment (<code class="docutils literal notranslate"><span class="pre">which</span> <span class="pre">pip</span></code> should point to something like <code class="docutils literal notranslate"><span class="pre">path/to/miniconda/envs/&lt;package_env_name&gt;/bin/pip</span></code>).</p>
<p>Once your package is installed, run the tests by typing:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>conda activate &lt;package_env_name&gt;
pytest
</pre></div>
</div>
<p>If the tests pass, you are good to go. If not, contact the package administrator Simon Adamov. Make sure to update your requirement files and export your environments after installation
every time you add new imports while developing. Check the next section to find some guidance on the development process if you are new to Python and/or APN.</p>
<section id="roadmap-to-your-first-contribution">
<h3>Roadmap to your first contribution<a class="headerlink" href="#roadmap-to-your-first-contribution" title="Permalink to this heading">¶</a></h3>
<p>Generally, the source code of your library is located in <code class="docutils literal notranslate"><span class="pre">src/&lt;library_name&gt;</span></code>. The blueprint will generate some example code in <code class="docutils literal notranslate"><span class="pre">mutable_number.py</span></code>, <code class="docutils literal notranslate"><span class="pre">utils.py</span></code> and <code class="docutils literal notranslate"><span class="pre">cli.py</span></code>. <code class="docutils literal notranslate"><span class="pre">cli.py</span></code> thereby serves as an entry
point for functionalities you want to execute from the command line, it is based on the Click library. If you do not need interactions with the command line, you should remove <code class="docutils literal notranslate"><span class="pre">cli.py</span></code>. Moreover, of course there exist other options for command line interfaces,
a good overview may be found here (<a class="reference external" href="https://realpython.com/comparing-python-command-line-parsing-libraries-argparse-docopt-click/">https://realpython.com/comparing-python-command-line-parsing-libraries-argparse-docopt-click/</a>), we recommend however to use click. The provided example
code should provide some guidance on how the individual source code files interact within the library. In addition to the example code in <code class="docutils literal notranslate"><span class="pre">src/&lt;library_name&gt;</span></code>, there are examples for
unit tests in <code class="docutils literal notranslate"><span class="pre">tests/&lt;library_name&gt;/</span></code>, which can be triggered with <code class="docutils literal notranslate"><span class="pre">pytest</span></code> from the command line. Once you implemented a feature (and of course you also
implemented a meaningful test ;-)), you are likely willing to commit it. First, go to the root directory of your package and run pytest.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>conda activate &lt;package_env_name&gt;
<span class="nb">cd</span> &lt;package-root-dir&gt;
pytest
</pre></div>
</div>
<p>If you use the tools provided by the blueprint as is, pre-commit will not be triggered locally but only if you push to the main branch
(or push to a PR to the main branch). If you consider it useful, you can set up pre-commit to run locally before every commit by initializing it once. In the root directory of
your package, type:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pre-commit install
</pre></div>
</div>
<p>If you run <code class="docutils literal notranslate"><span class="pre">pre-commit</span></code> without installing it before (line above), it will fail and the only way to recover it, is to do a forced reinstallation (<code class="docutils literal notranslate"><span class="pre">conda</span> <span class="pre">install</span> <span class="pre">--force-reinstall</span> <span class="pre">pre-commit</span></code>).
You can also just run pre-commit selectively, whenever you want by typing (<code class="docutils literal notranslate"><span class="pre">pre-commit</span> <span class="pre">run</span> <span class="pre">--all-files</span></code>). Note that mypy and pylint take a bit of time, so it is really
up to you, if you want to use pre-commit locally or not. In any case, after running pytest, you can commit and the linters will run at the latest on the GitHub actions server,
when you push your changes to the main branch. Note that pytest is currently not invoked by pre-commit, so it will not run automatically. Automated testing can be set up with
GitHub Actions or be implemented in a Jenkins pipeline (template for a plan available in <code class="docutils literal notranslate"><span class="pre">jenkins/</span></code>. See the next section for more details.</p>
</section>
</section>
<section id="development-tools">
<h2>Development tools<a class="headerlink" href="#development-tools" title="Permalink to this heading">¶</a></h2>
<p>As this package was created with the APN Python blueprint, it comes with a stack of development tools, which are described in more detail on
(<a class="reference external" href="https://meteoswiss-apn.github.io/mch-python-blueprint/">https://meteoswiss-apn.github.io/mch-python-blueprint/</a>). Here, we give a brief overview on what is implemented.</p>
<section id="testing-and-coding-standards">
<h3>Testing and coding standards<a class="headerlink" href="#testing-and-coding-standards" title="Permalink to this heading">¶</a></h3>
<p>Testing your code and compliance with the most important Python standards is a requirement for Python software written in APN. To make the life of package
administrators easier, the most important checks are run automatically on GitHub actions. If your code goes into production, it must additionally be tested on CSCS
machines, which is only possible with a Jenkins pipeline (GitHub actions is running on a GitHub server).</p>
</section>
<section id="pre-commit-on-github-actions">
<h3>Pre-commit on GitHub actions<a class="headerlink" href="#pre-commit-on-github-actions" title="Permalink to this heading">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">.github/workflows/pre-commit.yml</span></code> contains a hook that will trigger the creation of your environment (unpinned) on the GitHub actions server and
then run various formatters and linters through pre-commit. This hook is only triggered upon pushes to the main branch (in general: don’t do that)
and in pull requests to the main branch.</p>
</section>
<section id="jenkins">
<h3>Jenkins<a class="headerlink" href="#jenkins" title="Permalink to this heading">¶</a></h3>
<p>Two jenkins plans are available in the <code class="docutils literal notranslate"><span class="pre">jenkins/</span></code> folder. On the one hand <code class="docutils literal notranslate"><span class="pre">jenkins/Jenkinsfile</span></code> controls the nightly (weekly, monthly, …) builds, on the other hand
<code class="docutils literal notranslate"><span class="pre">jenkins/JenkinsJobPR</span></code> controls the pipeline invoked with the command <code class="docutils literal notranslate"><span class="pre">launch</span> <span class="pre">jenkins</span></code> in pull requests on GitHub. Your jenkins pipeline will not be set up
automatically. If you need to run your tests on CSCS machines, contact DevOps to help you with the setup of the pipelines. Otherwise, you can ignore the jenkinsfiles
and exclusively run your tests and checks on GitHub actions.</p>
</section>
</section>
<section id="features">
<h2>Features<a class="headerlink" href="#features" title="Permalink to this heading">¶</a></h2>
<p>This repo contains the code to train the Aldernet neural network model to predict surface level pollen concentrations.
To retrain the model simply run this command from the project root directory:</p>
<p><code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">src/aldernet/training.py</span></code></p>
<p>This main <strong>training.py</strong> script does the following (autogenerated by GPT-4):
This script is designed to train a U-Net based on COSMO-1e input data. The script sets up the environment, loads input and validation data, creates a generator, trains the model using hyperparameter search with Ray Tune, and saves the resulting model. After training, the script generates season predictions, scales them back to the original scale, and saves them as a NetCDF file and a CSV file. Lastly, it runs an R script to generate an HTML verification report.</p>
<p>Here’s an overview of the steps taken in the script:</p>
<ol class="arabic simple">
<li><p>Import required libraries and set up the environment.</p></li>
<li><p>Define various settings for the model and input data.</p></li>
<li><p>Load the training and validation data.</p></li>
<li><p>Set up the TensorFlow environment and random seed.</p></li>
<li><p>Set up the output directory and other necessary paths.</p></li>
<li><p>Compile the generator model and save its summary and architecture diagram.</p></li>
<li><p>Train the model using Ray Tune for hyperparameter search and save the best model.</p></li>
<li><p>If not using Ray Tune, train the model using a simple approach.</p></li>
<li><p>Generate season predictions using the best model.</p></li>
<li><p>Rescale the predictions back to the original scale.</p></li>
<li><p>Save the predictions as a NetCDF file and a CSV file.</p></li>
<li><p>Run an R script to generate an HTML verification report.</p></li>
</ol>
<p>Note that the script assumes that the input data is stored in specific directories depending on the hostname of the machine it is running on. If you want to run the script on your machine, you may need to adjust the input data paths accordingly.</p>
<p>As the training requires lots of computational resources, it is suggested to work on a HPC system.
For example at CSCS on the Balfrin cluster you can run this command:</p>
<p><code class="docutils literal notranslate"><span class="pre">srun</span> <span class="pre">-N1</span> <span class="pre">-n1</span> <span class="pre">--gres=gpu:4</span> <span class="pre">--job-name=MLFlow</span> <span class="pre">--time=23:59:00</span> <span class="pre">--partition=normal</span> <span class="pre">--account=s83</span> <span class="pre">python</span> <span class="pre">src/aldernet/training.py</span></code></p>
<p>The training is conducted by ray tune for parallel computations and hyper-parameter tuning and
MLFlow for logging and checkpointing.</p>
<p>Define training setting on lines 39-52 in the file <code class="docutils literal notranslate"><span class="pre">src/aldernet/training.py</span></code>
and paths to the input data on lines 54-79, before starting the training.
To use the data at the default path location you need access to the MeteoSwiss CSCS-Clusters.
This data is not freely available as of right now.</p>
<p>The following is a list of the most important files in this repo with a short explanation:</p>
<ul class="simple">
<li><p><strong>data</strong>:</p>
<ul>
<li><p><cite>fieldextra_alnu.nl/fieldextra_cory.nl</cite>: [<cite>Fieldextra</cite>](<a class="reference external" href="https://github.com/COSMO-ORG/fieldextra">https://github.com/COSMO-ORG/fieldextra</a>) namelist to retrieve Cosmo model output data</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">retrieve_dwh.sh</span></code>: retrieval of pollen station measurements from the MeteoSwiss Data-Warehouse</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scaling.txt</span></code>: the scaling applied to the Alder pollen concentrations before model training</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">species.RData/stations.RData</span></code>: lists containing names and abbreviations of pollen species and stations</p></li>
</ul>
</li>
<li><p><strong>notebooks</strong>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">analysis.Rmd</span></code>: statistical verification of modelled vs. measured concentrations at station level</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">example_cosmo_pollen.ipynp</span></code>: mapplot using Psyplot and Iconarray packages</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">profiling.ipynp</span></code>: descriptive statistics of input features and their correlations</p></li>
</ul>
</li>
<li><p><strong>src/aldernet:</strong></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">training.py</span></code>: the main script to start the training of the neural network</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">utils.py</span></code>: containing all functions required by the training.py script</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">plots.py</span></code>: creation of mapplots and animated gifs</p></li>
<li><p><strong>data:</strong></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">data_202X.py</span></code>: yearly aggregation of GRIB2 model output into zarr archives</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rechunk_zarr.py</span></code>: combined all yearly zarr archives into one and rechunk by valid_time</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data_utils.py</span></code>: various functions required by the other scripts in the data folder</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">create_batcher_input.np:</span></code> Preprocessing and train/test split of the data input</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section id="credits">
<h2>Credits<a class="headerlink" href="#credits" title="Permalink to this heading">¶</a></h2>
<p>This package was created with <code class="docutils literal notranslate"><span class="pre">`copier</span></code> &lt;<a class="reference external" href="https://github.com/copier-org/copier">https://github.com/copier-org/copier</a>&gt;`_ and the <code class="docutils literal notranslate"><span class="pre">`MeteoSwiss-APN/mch-python-blueprint</span></code> &lt;<a class="reference external" href="https://meteoswiss-apn.github.io/mch-python-blueprint/">https://meteoswiss-apn.github.io/mch-python-blueprint/</a>&gt;`_ project template.</p>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">Aldernet</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Aldernet</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#start-developing">Start developing</a></li>
<li class="toctree-l2"><a class="reference internal" href="#development-tools">Development tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="#features">Features</a></li>
<li class="toctree-l2"><a class="reference internal" href="#credits">Credits</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="modules.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="authors.html">Credits</a></li>
<li class="toctree-l1"><a class="reference internal" href="history.html">History</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="index.html" title="previous chapter">Welcome to Aldernet’s documentation!</a></li>
      <li>Next: <a href="installation.html" title="next chapter">Installation</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, MeteoSwiss.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 5.3.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/readme.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>